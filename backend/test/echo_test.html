<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebSocket Test Client (Diagnostic)</title>
    <style>
        body { font-family: sans-serif; margin: 20px; background-color: #f4f4f4; color: #333; }
        .container { background-color: #fff; padding: 20px; border-radius: 8px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }
        h1 { color: #333; }
        label { display: block; margin-top: 10px; }
        input[type="text"], select { width: calc(100% - 22px); padding: 10px; margin-top: 5px; border: 1px solid #ddd; border-radius: 4px; }
        button { padding: 10px 15px; margin-top: 15px; margin-right: 10px; border: none; border-radius: 4px; cursor: pointer; }
        .connect-btn { background-color: #28a745; color: white; }
        .disconnect-btn { background-color: #dc3545; color: white; }
        .record-btn { background-color: #007bff; color: white; }
        .stop-record-btn { background-color: #ffc107; color: black; }
        .play-btn { background-color: #6610f2; color: white; }
        #status { margin-top: 20px; padding: 10px; border: 1px solid #eee; border-radius: 4px; background-color: #e9ecef; }
        #messages { margin-top: 20px; padding: 10px; border: 1px solid #eee; border-radius: 4px; background-color: #f8f9fa; max-height: 200px; overflow-y: auto; white-space: pre-wrap; }
        .settings-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 10px; margin-top: 15px; }
        .settings-grid > div { margin-bottom: 10px; }
        .checkbox-container { display: flex; align-items: center; }
        .checkbox-container input { margin-right: 10px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>WebSocket Test Client (Diagnostic)</h1>
        <p style="color: blue; font-weight: bold;">
            This client sends raw 16-bit PCM (16kHz, mono) to the server.
            It can collect all received audio for a single playback after recording ends.
        </p>

        <div class="settings-grid">
            <div>
                <label for="sessionId">Session ID:</label>
                <input type="text" id="sessionId" value="test_session_001">
            </div>
            <div>
                <label for="endpointSelect">Select Endpoint:</label>
                <select id="endpointSelect">
                    <option value="stream/test/echo">Echo Test (/test/echo)</option>
                    <option value="test/vad">Vad Test (/test/vad)</option>
                    <option value="ws">Transcription (/ws)</option>
                    <option value="custom">Custom Endpoint</option>
                </select>
            </div>
            <div id="customEndpointContainer" style="display:none;">
                <label for="customEndpoint">Custom Endpoint Path (e.g., my/custom/endpoint):</label>
                <input type="text" id="customEndpoint" value="your/custom/path">
            </div>
            <div>
                <label for="serverAddress">WebSocket Server (host:port):</label>
                <input type="text" id="serverAddress" value="localhost:8000">
            </div>
        </div>

        <div class="checkbox-container">
            <input type="checkbox" id="collectAudioToggle" checked>
            <label for="collectAudioToggle">Collect all received audio for single playback</label>
        </div>

        <button id="connectButton" class="connect-btn">Connect</button>
        <button id="disconnectButton" class="disconnect-btn" disabled>Disconnect</button>
        <br>
        <button id="startRecordButton" class="record-btn" disabled>Start Recording & Sending PCM</button>
        <button id="stopRecordButton" class="stop-record-btn" disabled>Stop Recording</button>
        <button id="playCollectedButton" class="play-btn" disabled>Play Collected Audio</button>

        <div id="status">Not connected.</div>
        <h2>Log:</h2>
        <div id="messages"></div>
    </div>

    <script>
        const sessionIdInput = document.getElementById('sessionId');
        const endpointSelect = document.getElementById('endpointSelect');
        const customEndpointContainer = document.getElementById('customEndpointContainer');
        const customEndpointInput = document.getElementById('customEndpoint');
        const serverAddressInput = document.getElementById('serverAddress');
        const collectAudioToggle = document.getElementById('collectAudioToggle');
        const connectButton = document.getElementById('connectButton');
        const disconnectButton = document.getElementById('disconnectButton');
        const startRecordButton = document.getElementById('startRecordButton');
        const stopRecordButton = document.getElementById('stopRecordButton');
        const playCollectedButton = document.getElementById('playCollectedButton');
        const statusDiv = document.getElementById('status');
        const messagesDiv = document.getElementById('messages');

        let websocket = null;
        let mediaRecorder = null;
        let audioContext = null;
        let collectedPCM16Chunks = [];

        const TARGET_SAMPLE_RATE = 16000;
        const TIMESLICE_MS = 250; // << INCREASED for testing

        endpointSelect.addEventListener('change', () => {
            customEndpointContainer.style.display =
                endpointSelect.value === 'custom' ? 'block' : 'none';
        });

        collectAudioToggle.addEventListener('change', () => {
            if (!collectAudioToggle.checked) {
                collectedPCM16Chunks = [];
                playCollectedButton.disabled = true;
            }
            logMessage(`Audio collection: ${collectAudioToggle.checked ? 'ON' : 'OFF'}`);
        });

        async function processAudioBlobToSend(blob) {
            if (!audioContext) {
                logMessage("SendProc: Initializing AudioContext.");
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                logMessage(`SendProc: AudioContext state: ${audioContext.state}`);
            }

            // Resume context if suspended (important for some browsers after page load)
            if (audioContext.state === 'suspended') {
                logMessage("SendProc: AudioContext is suspended, attempting to resume...");
                try {
                    await audioContext.resume();
                    logMessage(`SendProc: AudioContext resumed. New state: ${audioContext.state}`);
                } catch (resumeError) {
                    logMessage(`ERR (SendProc AC Resume): ${resumeError.message}`);
                    console.error("AudioContext resume error:", resumeError);
                    return null; // Cannot proceed if context can't be resumed
                }
            }


            try {
                const arrayBuffer = await blob.arrayBuffer();
                if (arrayBuffer.byteLength === 0) {
                    logMessage("ERR (SendProc): Received empty ArrayBuffer from Blob.");
                    return null;
                }
                logMessage(`SendProc: Blob converted to ArrayBuffer, size: ${arrayBuffer.byteLength}B. Decoding...`);

                const decodedAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                logMessage(`SendProc: Decoded. Original SR: ${decodedAudioBuffer.sampleRate}Hz, Ch: ${decodedAudioBuffer.numberOfChannels}, Dur: ${decodedAudioBuffer.duration.toFixed(3)}s`);

                let resampledBuffer;
                if (decodedAudioBuffer.sampleRate === TARGET_SAMPLE_RATE && decodedAudioBuffer.numberOfChannels === 1) {
                    resampledBuffer = decodedAudioBuffer;
                    logMessage("SendProc: No resampling needed.");
                } else {
                    logMessage(`SendProc: Resampling to ${TARGET_SAMPLE_RATE}Hz, 1Ch...`);
                    const targetLength = Math.ceil(decodedAudioBuffer.duration * TARGET_SAMPLE_RATE);
                     if (targetLength === 0) {
                        logMessage("ERR (SendProc): Resampling target length is 0. Original duration might be too small or 0.");
                        return null;
                    }
                    const offlineContext = new OfflineAudioContext(1, targetLength, TARGET_SAMPLE_RATE);
                    const bufferSource = offlineContext.createBufferSource();
                    bufferSource.buffer = decodedAudioBuffer;
                    bufferSource.connect(offlineContext.destination);
                    bufferSource.start(0);
                    resampledBuffer = await offlineContext.startRendering();
                    logMessage(`SendProc: Resampled. New SR: ${resampledBuffer.sampleRate}Hz, Ch: ${resampledBuffer.numberOfChannels}, Dur: ${resampledBuffer.duration.toFixed(3)}s`);
                }
                const pcm16TypedArray = convertFloat32ToInt16(resampledBuffer.getChannelData(0));
                logMessage(`SendProc: Converted to PCM16. Samples: ${pcm16TypedArray.length}`);
                return pcm16TypedArray.buffer;
            } catch (error) {
                logMessage(`ERR (SendProc): ${error.message}. Blob size: ${blob.size}, type: ${blob.type}`);
                console.error("Audio processing error for sending:", error, "Blob details:", blob);
                return null;
            }
        }

        function convertFloat32ToInt16(float32Array) {
            // ... (no change)
            const pcm16Array = new Int16Array(float32Array.length);
            for (let i = 0; i < float32Array.length; i++) {
                let s = Math.max(-1, Math.min(1, float32Array[i]));
                pcm16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return pcm16Array;
        }

        function convertInt16ToFloat32(int16Array) {
            // ... (no change)
            const float32Array = new Float32Array(int16Array.length);
            for (let i = 0; i < int16Array.length; i++) {
                float32Array[i] = int16Array[i] / (int16Array[i] < 0 ? 0x8000 : 0x7FFF);
            }
            return float32Array;
        }

        async function handleReceivedPCM(pcmArrayBuffer, isFinalCollectedPlayback = false) {
            // ... (no change from previous correct version)
            if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
            if (!pcmArrayBuffer || pcmArrayBuffer.byteLength === 0) {
                logMessage("PCM Recv: Empty.");
                return;
            }

            const pcm16View = new Int16Array(pcmArrayBuffer);

            if (!isFinalCollectedPlayback && collectAudioToggle.checked) {
                collectedPCM16Chunks.push(pcm16View);
                logMessage(`PCM Collect: Chunk (${pcmArrayBuffer.byteLength}B). Total: ${collectedPCM16Chunks.length}`);
                return;
            }

            try {
                const float32Array = convertInt16ToFloat32(pcm16View);
                const audioBuffer = audioContext.createBuffer(1, float32Array.length, TARGET_SAMPLE_RATE);
                audioBuffer.getChannelData(0).set(float32Array);

                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.start();
                logMessage(`PCM Play: (${pcmArrayBuffer.byteLength}B).`);
            } catch (error) {
                logMessage(`ERR (PCM Play): ${error.message}`);
                console.error("Error playing raw PCM:", error);
            }
        }

        function playCollectedAudio() {
            // ... (no change from previous correct version)
             if (collectedPCM16Chunks.length === 0) {
                logMessage("PlayCollect: No audio.");
                return;
            }
            let totalLength = 0;
            collectedPCM16Chunks.forEach(chunk => totalLength += chunk.length);
            const combinedInt16 = new Int16Array(totalLength);
            let offset = 0;
            collectedPCM16Chunks.forEach(chunk => {
                combinedInt16.set(chunk, offset);
                offset += chunk.length;
            });
            logMessage(`PlayCollect: ${collectedPCM16Chunks.length} chunks, ${totalLength} samples, ${combinedInt16.byteLength}B.`);
            handleReceivedPCM(combinedInt16.buffer, true);
        }

        connectButton.onclick = () => {
            // ... (no change from previous correct version)
            const sessionId = sessionIdInput.value.trim();
            const serverAddress = serverAddressInput.value.trim();
            if (!sessionId || !serverAddress) {
                alert("Session ID and Server Address required."); return;
            }

            let endpointPathSegment = endpointSelect.value;
            if (endpointPathSegment === 'custom') {
                endpointPathSegment = customEndpointInput.value.trim();
                if (!endpointPathSegment) { alert("Custom endpoint path required."); return; }
            }
            const wsUrl = `ws://${serverAddress}/${endpointPathSegment}/${sessionId}`;

            statusDiv.textContent = `Connecting to ${wsUrl}...`;
            websocket = new WebSocket(wsUrl);
            websocket.binaryType = "arraybuffer";

            websocket.onopen = () => {
                statusDiv.textContent = `Connected: ${wsUrl}`;
                logMessage(`Connected: ${wsUrl}.`);
                connectButton.disabled = true; disconnectButton.disabled = false; startRecordButton.disabled = false;
                [sessionIdInput, serverAddressInput, endpointSelect, customEndpointInput].forEach(el => el.disabled = true);
                if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
                collectedPCM16Chunks = [];
                playCollectedButton.disabled = true;
            };

            websocket.onmessage = async (event) => { // ... (no change from previous correct version)
                const currentEndpoint = endpointSelect.value;

                if (event.data instanceof ArrayBuffer) {
                    if (currentEndpoint === 'test/echo' || currentEndpoint === 'test/vad') {
                        logMessage(`PCM Recv: ${event.data.byteLength}B from ${currentEndpoint}.`);
                        await handleReceivedPCM(event.data);
                    } else {
                        try {
                            const textData = new TextDecoder('utf-8', { fatal: true }).decode(event.data);
                            const jsonData = JSON.parse(textData);
                            logMessage(`JSON (from AB): ${JSON.stringify(jsonData)}`);
                            if (jsonData.event && (jsonData.event === 'transcript' || jsonData.event === 'final_transcript')) {
                                 messagesDiv.innerHTML += `<p><strong>[${jsonData.event}]</strong> ${jsonData.transcript || ''}</p>`;
                                 messagesDiv.scrollTop = messagesDiv.scrollHeight;
                            }
                        } catch (e) {
                             logMessage(`WARN: Recv ArrayBuffer from ${currentEndpoint}, not valid UTF-8 JSON. Size: ${event.data.byteLength}B. Error: ${e.message}`);
                             if (currentEndpoint === 'custom') {
                                 logMessage('Custom endpoint sent ArrayBuffer, trying as PCM.');
                                 await handleReceivedPCM(event.data);
                             }
                        }
                    }
                } else if (typeof event.data === 'string') {
                    logMessage(`Text Recv: "${event.data.substring(0,100)}${event.data.length > 100 ? '...' : ''}" from ${currentEndpoint}`);
                     try {
                        const jsonData = JSON.parse(event.data);
                        if (jsonData.event && (jsonData.event === 'transcript' || jsonData.event === 'final_transcript')) {
                             messagesDiv.innerHTML += `<p><strong>[${jsonData.event}]</strong> ${jsonData.transcript || ''}</p>`;
                             messagesDiv.scrollTop = messagesDiv.scrollHeight;
                        } else {
                            logMessage(`JSON (from Str): ${JSON.stringify(jsonData)}`);
                        }
                     } catch (e) {
                        logMessage(`ERR: Could not parse text as JSON: ${e.message}`);
                     }
                } else if (event.data instanceof Blob) {
                    logMessage(`Blob Recv: ${event.data.size}B, type: ${event.data.type}. Processing...`);
                    const arrayBuffer = await event.data.arrayBuffer();
                    try {
                        const decoded = await audioContext.decodeAudioData(arrayBuffer);
                        const pcm16Data = convertFloat32ToInt16(decoded.getChannelData(0));
                        if (collectAudioToggle.checked) {
                            collectedPCM16Chunks.push(pcm16Data);
                            logMessage(`Collected decoded Blob as PCM: ${pcm16Data.byteLength}B.`);
                        } else {
                            await handleReceivedPCM(pcm16Data.buffer);
                        }
                    } catch (e) {
                        logMessage(`ERR (Blob Proc): ${e.message}`);
                    }
                } else {
                    logMessage(`Recv Unknown: type ${typeof event.data}`);
                }
            };
            websocket.onerror = (error) => { // ... (no change from previous correct version)
                console.error("WebSocket Error:", error);
                statusDiv.textContent = "WebSocket error.";
                logMessage(`ERR (WS): ${(error && error.message) || 'Unknown WebSocket error'}`);
                resetUI();
            };
            websocket.onclose = (event) => { // ... (no change from previous correct version)
                statusDiv.textContent = `Disconnected. Code: ${event.code}, Reason: ${event.reason || 'N/A'}`;
                logMessage(`WS Closed. Code: ${event.code}, Reason: ${event.reason || 'N/A'}`);
                resetUI();
                if (mediaRecorder && mediaRecorder.state === "recording") mediaRecorder.stop();
            };
        };

        disconnectButton.onclick = () => { // ... (no change from previous correct version)
            if (websocket) websocket.close();
            if (mediaRecorder && mediaRecorder.state === "recording") mediaRecorder.stop();
        };

        startRecordButton.onclick = async () => {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                alert("getUserMedia not supported!"); return;
            }
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: {
                    sampleRate: { ideal: 48000 }, // Request a common high rate, will resample anyway
                    channelCount: 1
                }});
                const trackSettings = stream.getAudioTracks()[0].getSettings();
                logMessage(`Mic: SR=${trackSettings.sampleRate}Hz, Ch=${trackSettings.channelCount}`);

                const options = {};
                const supportedTypes = [
                    'audio/webm; codecs=opus',
                    'audio/ogg; codecs=opus',
                    'audio/aac', // Another common one, though not as ideal for this as Opus
                    'audio/mp4', // Sometimes browsers use this with AAC
                    // 'audio/wav' // Usually not supported by MediaRecorder for streaming
                ];
                for (const type of supportedTypes) {
                    if (MediaRecorder.isTypeSupported(type)) {
                        options.mimeType = type;
                        logMessage(`MediaRecorder using: ${type}`);
                        break;
                    }
                }
                if (!options.mimeType) {
                     logMessage("WARN: No preferred mimeType supported. Using browser default.");
                }

                mediaRecorder = new MediaRecorder(stream, options);

                mediaRecorder.ondataavailable = async (event) => {
                    if (event.data.size > 0 && websocket && websocket.readyState === WebSocket.OPEN) {
                        logMessage(`ondataavailable: Blob type: ${event.data.type}, size: ${event.data.size}B`); // DIAGNOSTIC
                        const pcmBuffer = await processAudioBlobToSend(event.data);
                        if (pcmBuffer) {
                            websocket.send(pcmBuffer);
                            logMessage(`PCM Sent: ${pcmBuffer.byteLength}B.`);
                        } else {
                            logMessage("PCM SendProc: Failed.");
                        }
                    }
                };
                mediaRecorder.onstart = () => { // ... (no change from previous correct version)
                    logMessage("Recording started...");
                    startRecordButton.disabled = true; stopRecordButton.disabled = false;
                    playCollectedButton.disabled = true;
                    collectedPCM16Chunks = [];
                };
                mediaRecorder.onstop = () => { // ... (no change from previous correct version)
                    logMessage("Recording stopped.");
                    startRecordButton.disabled = false; stopRecordButton.disabled = true;
                    stream.getTracks().forEach(track => track.stop());
                    if (collectAudioToggle.checked && collectedPCM16Chunks.length > 0) {
                        playCollectedButton.disabled = false;
                    }
                };
                mediaRecorder.start(TIMESLICE_MS);
            } catch (err) {
                console.error("Mic/MediaRecorder Error:", err);
                logMessage(`ERR (Mic/MR): ${err.message}`);
                statusDiv.textContent = "Mic/MediaRecorder error.";
            }
        };

        stopRecordButton.onclick = () => { // ... (no change from previous correct version)
            if (mediaRecorder && mediaRecorder.state === "recording") mediaRecorder.stop();
        };
        playCollectedButton.onclick = playCollectedAudio; // ... (no change from previous correct version)
        function logMessage(message) { // ... (no change from previous correct version)
            const p = document.createElement('p');
            const timestamp = new Date().toLocaleTimeString([], { hour12: false });
            p.textContent = `[${timestamp}] ${message}`;
            messagesDiv.appendChild(p);
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }
        function resetUI() { // ... (no change from previous correct version)
            connectButton.disabled = false; disconnectButton.disabled = true;
            startRecordButton.disabled = true; stopRecordButton.disabled = true;
            [sessionIdInput, serverAddressInput, endpointSelect, customEndpointInput].forEach(el => el.disabled = false);
            playCollectedButton.disabled = !(collectAudioToggle.checked && collectedPCM16Chunks.length > 0);
            if (mediaRecorder && mediaRecorder.state === "recording") mediaRecorder.stop();
            mediaRecorder = null;
        }

        endpointSelect.dispatchEvent(new Event('change'));
    </script>
</body>
</html>